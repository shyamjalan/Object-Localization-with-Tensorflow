{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing The Required Libraries\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameters\n",
    "epochs = 150\n",
    "step_size = 8\n",
    "IMG_SIZE_ALEXNET = 227 # image size\n",
    "validating_size = 20 # while cross validating, we are evaluating batch by batch\n",
    "nodes_fc1 = 4096 # no of nodes on fc layer 1\n",
    "nodes_fc2 = 4096 # no of nodes on fc layer 2\n",
    "output_locations = 4 # x1,x2,y1,y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating train and validation sets\n",
    "X_train = np.load('object_localization.npy')\n",
    "y = np.load('object_localization_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating train and validation sets\n",
    "train = data[:int(len(data)*0.8)]\n",
    "cv = data[int(len(data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X for train input\n",
    "X = np.array(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11200, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = y[:int(len(y)*0.8)]\n",
    "Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_x for train input\n",
    "cv_x = np.array(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_y2 = y[int(len(y)*0.8):]\n",
    "cv_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200\n"
     ]
    }
   ],
   "source": [
    "#How many training images are kept as 'steps'\n",
    "steps = len(train)\n",
    "print(steps)\n",
    "remaining = steps % step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting graph\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Placeholders\n",
    "x = tf.placeholder(tf.float32,shape=[None,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3])\n",
    "y_true_2 = tf.placeholder(tf.float32,shape=[None,output_locations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(?, 55, 55, 96), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##CONVOLUTION LAYER 1\n",
    "#Weights for layer 1\n",
    "w_1 = tf.Variable(tf.truncated_normal([11,11,3,96], stddev=0.01))\n",
    "#Bias for layer 1\n",
    "b_1 = tf.Variable(tf.constant(0.0, shape=[96]))\n",
    "#Applying convolution\n",
    "c_1 = tf.nn.conv2d(x, w_1,strides=[1, 4, 4, 1], padding='VALID')\n",
    "#Adding bias\n",
    "c_1 = c_1 + b_1\n",
    "#Applying RELU\n",
    "c_1 = tf.nn.relu(c_1)\n",
    "print(c_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool:0\", shape=(?, 27, 27, 96), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##POOLING LAYER1\n",
    "p_1 = tf.nn.max_pool(c_1, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_1:0\", shape=(?, 27, 27, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##CONVOLUTION LAYER 2\n",
    "#Weights for layer 2\n",
    "w_2 = tf.Variable(tf.truncated_normal([5,5,96,256], stddev=0.01))\n",
    "#Bias for layer 2\n",
    "b_2 = tf.Variable(tf.constant(1.0, shape=[256]))\n",
    "#Applying convolution\n",
    "c_2 = tf.nn.conv2d(p_1, w_2,strides=[1, 1, 1, 1], padding='SAME')\n",
    "#Adding bias\n",
    "c_2 = c_2 + b_2\n",
    "#Applying RELU\n",
    "c_2 = tf.nn.relu(c_2)\n",
    "print(c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##POOLING LAYER2\n",
    "p_2 = tf.nn.max_pool(c_2, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
    "print(p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##CONVOLUTION LAYER 3\n",
    "#Weights for layer 3\n",
    "w_3 = tf.Variable(tf.truncated_normal([3, 3, 256, 384], stddev=0.01))\n",
    "#Bias for layer 3\n",
    "b_3 = tf.Variable(tf.constant(0.0, shape=[384]))\n",
    "#Applying convolution\n",
    "c_3 = tf.nn.conv2d(p_2, w_3,strides=[1, 1, 1, 1], padding='SAME')\n",
    "#Adding bias\n",
    "c_3 = c_3 + b_3\n",
    "#Applying RELU\n",
    "c_3 = tf.nn.relu(c_3)\n",
    "print(c_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_3:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##CONVOLUTION LAYER 4\n",
    "#Weights for layer 4\n",
    "w_4 = tf.Variable(tf.truncated_normal([3, 3, 384, 384], stddev=0.01))\n",
    "#Bias for layer 4\n",
    "b_4 = tf.Variable(tf.constant(0.0, shape=[384]))\n",
    "#Applying convolution\n",
    "c_4 = tf.nn.conv2d(c_3, w_4,strides=[1, 1, 1, 1], padding='SAME')\n",
    "#Adding bias\n",
    "c_4 = c_4 + b_4\n",
    "#Applying RELU\n",
    "c_4 = tf.nn.relu(c_4)\n",
    "print(c_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_4:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##CONVOLUTION LAYER 5\n",
    "#Weights for layer 5\n",
    "w_5 = tf.Variable(tf.truncated_normal([3, 3, 384, 256], stddev=0.01))\n",
    "#Bias for layer 5\n",
    "b_5 = tf.Variable(tf.constant(0.0, shape=[256]))\n",
    "#Applying convolution\n",
    "c_5 = tf.nn.conv2d(c_4, w_5,strides=[1, 1, 1, 1], padding='SAME')\n",
    "#Adding bias\n",
    "c_5 = c_5 + b_5\n",
    "#Applying RELU\n",
    "c_5 = tf.nn.relu(c_5)\n",
    "print(c_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(?, 6, 6, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##POOLING LAYER3\n",
    "p_3 = tf.nn.max_pool(c_5, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
    "print(p_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 9216), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Flattening\n",
    "flattened = tf.reshape(p_3,[-1,6*6*256])\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fully Connected Layer 1\n",
    "#Getting input nodes in FC layer 1\n",
    "input_size = int( flattened.get_shape()[1] )\n",
    "#Weights for FC Layer 1\n",
    "w1_fc = tf.Variable(tf.truncated_normal([input_size, nodes_fc1], stddev=0.01))\n",
    "#Bias for FC Layer 1\n",
    "b1_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc1] ) )\n",
    "#Summing Matrix calculations and bias\n",
    "s_fc1 = tf.matmul(flattened, w1_fc) + b1_fc\n",
    "#Applying RELU\n",
    "s_fc1 = tf.nn.relu(s_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout/mul:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Dropout Layer 1\n",
    "hold_prob1 = tf.placeholder(tf.float32)\n",
    "s_fc1 = tf.nn.dropout(s_fc1,keep_prob=hold_prob1)\n",
    "print(s_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_6:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##Fully Connected Layer 2\n",
    "#Weights for FC Layer 2\n",
    "w2_fc = tf.Variable(tf.truncated_normal([nodes_fc1, nodes_fc2], stddev=0.01))\n",
    "#Bias for FC Layer 2\n",
    "b2_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc2] ) )\n",
    "#Summing Matrix calculations and bias\n",
    "s_fc2 = tf.matmul(s_fc1, w2_fc) + b2_fc\n",
    "#Applying RELU\n",
    "s_fc2 = tf.nn.relu(s_fc2)\n",
    "print(s_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropout Layer 2\n",
    "hold_prob2 = tf.placeholder(tf.float32)\n",
    "s_fc2 = tf.nn.dropout(s_fc2,keep_prob=hold_prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_7:0\", shape=(?, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##Fully Connected Layer 3 -- REGRESSION HEAD\n",
    "#Weights for FC Layer 3\n",
    "w3_fc_2 = tf.Variable(tf.truncated_normal([nodes_fc2,output_locations], stddev=0.01))\n",
    "#Bias for FC Layer 3b3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n",
    "b3_fc_2 = tf.Variable( tf.constant(1.0, shape=[output_locations] ) )\n",
    "#Summing Matrix calculations and bias\n",
    "y_pred_2 = tf.matmul(s_fc2, w3_fc_2) + b3_fc_2\n",
    "#Applying RELU\n",
    "print(y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Regression Loss\n",
    "regression_loss = tf.multiply(tf.reduce_mean(tf.square(y_pred_2 - y_true_2)),1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_loss = regression_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining objective function\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(final_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing weights\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting Empty lists to keep results\n",
    "regression_list = []\n",
    "#In order to save, creating a tf.train.Saver() object.\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU settings\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "tf.add_to_collection(\"regression_head\", y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-12 07:44:52.495998\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1  ====>  1424094.045578003\n",
      "Epoch # 2  ====>  620275.1808776855\n",
      "Epoch # 3  ====>  513350.40882873535\n",
      "Epoch # 4  ====>  435124.075302124\n",
      "Epoch # 5  ====>  377055.2024040222\n",
      "Epoch # 6  ====>  335593.94770622253\n",
      "Epoch # 7  ====>  303683.09481811523\n",
      "Epoch # 8  ====>  278515.79860305786\n",
      "Epoch # 9  ====>  260648.21522521973\n",
      "Epoch # 10  ====>  242485.3102054596\n",
      "Epoch # 11  ====>  228798.32899093628\n",
      "Epoch # 12  ====>  213754.29935455322\n",
      "Epoch # 13  ====>  199259.44234466553\n",
      "Epoch # 14  ====>  192453.19703292847\n",
      "Epoch # 15  ====>  177772.89972877502\n",
      "Epoch # 16  ====>  170328.9782218933\n",
      "Epoch # 17  ====>  159164.95582199097\n",
      "Epoch # 18  ====>  151128.22874641418\n",
      "Epoch # 19  ====>  142570.7325630188\n",
      "Epoch # 20  ====>  132267.46536254883\n",
      "Epoch # 21  ====>  124360.31617546082\n",
      "Epoch # 22  ====>  118896.71995544434\n",
      "Epoch # 23  ====>  111421.74781036377\n",
      "Epoch # 24  ====>  105718.66763973236\n",
      "Epoch # 25  ====>  100218.8476486206\n",
      "Epoch # 26  ====>  96794.76226329803\n",
      "Epoch # 27  ====>  92685.83761787415\n",
      "Epoch # 28  ====>  87609.52165412903\n",
      "Epoch # 29  ====>  83963.20408153534\n",
      "Epoch # 30  ====>  81735.85350894928\n",
      "Epoch # 31  ====>  78032.58916473389\n",
      "Epoch # 32  ====>  74838.75679206848\n",
      "Epoch # 33  ====>  73184.41010284424\n",
      "Epoch # 34  ====>  70429.06178760529\n",
      "Epoch # 35  ====>  67676.9976348877\n",
      "Epoch # 36  ====>  66033.56340026855\n",
      "Epoch # 37  ====>  63674.66772270203\n",
      "Epoch # 38  ====>  62576.04057598114\n",
      "Epoch # 39  ====>  62943.96458148956\n",
      "Epoch # 40  ====>  59073.18595504761\n",
      "Epoch # 41  ====>  58382.78261470795\n",
      "Epoch # 42  ====>  57101.62075805664\n",
      "Epoch # 43  ====>  55179.24470329285\n",
      "Epoch # 44  ====>  54710.59174633026\n",
      "Epoch # 45  ====>  54582.99955368042\n",
      "Epoch # 46  ====>  52192.526492118835\n",
      "Epoch # 47  ====>  52682.277247428894\n",
      "Epoch # 48  ====>  50827.002009391785\n",
      "Epoch # 49  ====>  51225.30960083008\n",
      "Epoch # 50  ====>  49309.36430835724\n",
      "Epoch # 51  ====>  48389.31002044678\n",
      "Epoch # 52  ====>  47957.2490735054\n",
      "Epoch # 53  ====>  47508.59952163696\n",
      "Epoch # 54  ====>  46438.339374542236\n",
      "Epoch # 55  ====>  46849.55325984955\n",
      "Epoch # 56  ====>  46269.88328266144\n",
      "Epoch # 57  ====>  45192.11198616028\n",
      "Epoch # 58  ====>  45048.8544216156\n",
      "Epoch # 59  ====>  44153.09165287018\n",
      "Epoch # 60  ====>  43438.689467430115\n",
      "Epoch # 61  ====>  43271.953443050385\n",
      "Epoch # 62  ====>  42763.342047691345\n",
      "Epoch # 63  ====>  42623.293811798096\n",
      "Epoch # 64  ====>  42585.756429195404\n",
      "Epoch # 65  ====>  41923.24537277222\n",
      "Epoch # 66  ====>  41996.07022380829\n",
      "Epoch # 67  ====>  41138.78053379059\n",
      "Epoch # 68  ====>  40511.02596759796\n",
      "Epoch # 69  ====>  40869.74855136871\n",
      "Epoch # 70  ====>  40681.94931316376\n",
      "Epoch # 71  ====>  39704.71668434143\n",
      "Epoch # 72  ====>  40023.20199584961\n",
      "Epoch # 73  ====>  39336.40393924713\n",
      "Epoch # 74  ====>  38879.808824539185\n",
      "Epoch # 75  ====>  39493.872034072876\n",
      "Epoch # 76  ====>  39185.63093948364\n",
      "Epoch # 77  ====>  38773.33990192413\n",
      "Epoch # 78  ====>  37911.999406814575\n",
      "Epoch # 79  ====>  38531.83549404144\n",
      "Epoch # 80  ====>  38330.50646305084\n",
      "Epoch # 81  ====>  37379.33491420746\n",
      "Epoch # 82  ====>  37482.59070587158\n",
      "Epoch # 83  ====>  37941.12219953537\n",
      "Epoch # 84  ====>  37253.9560008049\n",
      "Epoch # 85  ====>  36692.470989227295\n",
      "Epoch # 86  ====>  37299.78504037857\n",
      "Epoch # 87  ====>  36464.101843357086\n",
      "Epoch # 88  ====>  36284.78075361252\n",
      "Epoch # 89  ====>  36559.27449989319\n",
      "Epoch # 90  ====>  36239.162539958954\n",
      "Epoch # 91  ====>  35833.496534347534\n",
      "Epoch # 92  ====>  36094.6167550087\n",
      "Epoch # 93  ====>  35394.91006422043\n",
      "Epoch # 94  ====>  35461.35076713562\n",
      "Epoch # 95  ====>  35650.79918575287\n",
      "Epoch # 96  ====>  35089.910348415375\n",
      "Epoch # 97  ====>  35197.27550983429\n",
      "Epoch # 98  ====>  34773.85752725601\n",
      "Epoch # 99  ====>  35263.52368974686\n",
      "Epoch # 100  ====>  34473.74094724655\n",
      "Epoch # 101  ====>  34245.06421804428\n",
      "Epoch # 102  ====>  34296.94114589691\n",
      "Epoch # 103  ====>  34484.1115231514\n",
      "Epoch # 104  ====>  33812.14925670624\n",
      "Epoch # 105  ====>  33705.73365688324\n",
      "Epoch # 106  ====>  34100.7063832283\n",
      "Epoch # 107  ====>  34212.94564771652\n",
      "Epoch # 108  ====>  33532.63585519791\n",
      "Epoch # 109  ====>  34040.00728416443\n",
      "Epoch # 110  ====>  34003.45763254166\n",
      "Epoch # 111  ====>  33613.96809673309\n",
      "Epoch # 112  ====>  33529.487362384796\n",
      "Epoch # 113  ====>  32908.24753665924\n",
      "Epoch # 114  ====>  32793.14814329147\n",
      "Epoch # 115  ====>  33347.03113365173\n",
      "Epoch # 116  ====>  33629.47934818268\n",
      "Epoch # 117  ====>  32482.873725891113\n",
      "Epoch # 118  ====>  32813.57558250427\n",
      "Epoch # 119  ====>  32705.61970281601\n",
      "Epoch # 120  ====>  32493.660509586334\n",
      "Epoch # 121  ====>  32061.84005880356\n",
      "Epoch # 122  ====>  32999.5373916626\n",
      "Epoch # 123  ====>  32124.50212955475\n",
      "Epoch # 124  ====>  33000.00017929077\n",
      "Epoch # 125  ====>  32343.732296466827\n",
      "Epoch # 126  ====>  31919.63881635666\n",
      "Epoch # 127  ====>  32311.90429210663\n",
      "Epoch # 128  ====>  32573.441326141357\n",
      "Epoch # 129  ====>  32097.81593990326\n",
      "Epoch # 130  ====>  32124.281138896942\n",
      "Epoch # 131  ====>  31981.97357082367\n",
      "Epoch # 132  ====>  31828.652748584747\n",
      "Epoch # 133  ====>  31614.924102306366\n",
      "Epoch # 134  ====>  31366.44998407364\n",
      "Epoch # 135  ====>  31016.141723632812\n",
      "Epoch # 136  ====>  31633.643933296204\n",
      "Epoch # 137  ====>  31722.212764263153\n",
      "Epoch # 138  ====>  31097.401074409485\n",
      "Epoch # 139  ====>  31049.085089206696\n",
      "Epoch # 140  ====>  31394.692001342773\n",
      "Epoch # 141  ====>  31544.021473407745\n",
      "Epoch # 142  ====>  31076.587380886078\n",
      "Epoch # 143  ====>  31454.007598400116\n",
      "Epoch # 144  ====>  31033.41902446747\n",
      "Epoch # 145  ====>  31133.491456508636\n",
      "Epoch # 146  ====>  30443.421523094177\n",
      "Epoch # 147  ====>  31171.594129562378\n",
      "Epoch # 148  ====>  30280.92532157898\n",
      "Epoch # 149  ====>  30945.34231185913\n",
      "Epoch # 150  ====>  30366.8146777153\n",
      "Training has finished and model is saved\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(epochs):\n",
    "            total_cost = 0\n",
    "            for j in range(0,steps-remaining,step_size):\n",
    "                #Feeding step_size-amount data with 0.5 keeping probabilities on DROPOUT LAYERS\n",
    "                _,c = sess.run([train,final_loss],feed_dict = {x:X[j:j+step_size], y_true_2:Y2[j:j+step_size],hold_prob1:0.5,hold_prob2:0.5})\n",
    "                total_cost += c\n",
    "            print(\"Epoch #\",i+1,\" ====> \",total_cost)\n",
    "#Writing for loop to calculate test statistics. GTX 1060 isn't able to calculate all cv data.\n",
    "            cv_regression_list = []\n",
    "            for v in range(0,len(cv_x)-int(len(cv_x) % validating_size),validating_size):\n",
    "                coordinates = sess.run([y_pred_2],feed_dict={x:cv_x[v:v+validating_size],hold_prob1:1.0,hold_prob2:1.0})\n",
    "                regression_loss = np.mean(pow(cv_y2[v:v+validating_size] - coordinates , 2 ) )\n",
    "                cv_regression_list.append(regression_loss)\n",
    "            regression_loss_cv_ = round(np.mean(cv_regression_list),5)\n",
    "            regression_list.append(regression_loss_cv_)\n",
    "        print(\"Training has finished and model is saved\")\n",
    "        saver.save(sess, os.path.join(os.getcwd(),\"CNN_final.ckpt\"))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-12 10:30:57.470116\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
